{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6Nw6Ok35GdU"
   },
   "source": [
    "# Tarea #4: MA5203 Aprendizaje de Máquinas Probabilístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UK5zZD3g5GdW"
   },
   "source": [
    "##  Redes Neuronales y MNIST (75%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtI98D2W5GdX"
   },
   "source": [
    "En esta tarea deberán implementar una __red neuronal convolucional__ (CNN) profunda para resolver el problema de clasificación de las imágenes de dígitos escritos a mano (MNIST), en donde se espera que alcancen mayores niveles de accuracy que con la red neuronal feedforward mostrada en el tutorial de TensorFlow.\n",
    "\n",
    "Para esto:\n",
    "> + Diseñarán la arquitectura de una red convolucional <br>\n",
    "> + Ajustarán un algoritmo de optimización de su preferencia <br>\n",
    "> + Regularizarán la red neuronal <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JW3_xaHz5GdY"
   },
   "source": [
    "### 1) Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fAhxezlL5GdY"
   },
   "source": [
    "Debe entregar el Jupyter Notebook completando en el código las secciones indicadas y señalizadas específicamente por (...). Puede agregar o quitar partes del diseño de la arquitectura como estime conveniente. También deberá entregar un informe de __máximo 2 planas__ que incluya:\n",
    "\n",
    "> + Arquitectura de la red <br>\n",
    "> + Ajuste de hiperparámetros y optimizador elegido<br>\n",
    "> + Regularización y entrenamiento <br>\n",
    "> + Presentación de resultados <br>\n",
    "> + Análisis de resultados y conclusiones <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sSvOpFFE5GdZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1I5SBjxx5Gdf"
   },
   "source": [
    "### 2) Fase de construcción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haly_0GN5Gdh"
   },
   "source": [
    "La primera función a construir es _deepnn()_, que construye el grafo con la arquitectura de la red convolucional con la que se resolverá el problema. Esta debe contener la siguiente estructura (como mínimo) dentro de los _name scopes_:\n",
    "+ 'reshape': haz un reshape al input para usarlo dentro de una red convolucional (https://www.tensorflow.org/api_docs/python/tf/reshape) <br>\n",
    "+ capa de convolución (se recomienda más de 1):\n",
    "> + 'conv': capa de convolución <br>\n",
    "> + 'pool': capa de pooling <br>\n",
    "> + 'fc': capa fully connected <br>\n",
    "+ 'droput': máscara de dropout para regularización (puede usar otra técnica) (https://www.tensorflow.org/api_docs/python/tf/nn/dropout) <br>\n",
    "+ 'cl_layer': capa de clasificación <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nX1kOy3I5Gdh"
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "    \"\"\"\n",
    "  Función que construye el grafo de una red profunda\n",
    "  \n",
    "  --------PUEDE AGREGAR O QUITAR ELEMENTOS DE LA CAPA PREDEFINIDA MÁS ADELANTE------\n",
    "  \n",
    "  Args:\n",
    "    x: tensor de input con dimensiones (N_examples, 784)\n",
    "  Returns:\n",
    "    Una tupla (y, keep_prob), con y un tensor de dimensión (N_examples, 10),\n",
    "    con los valores de los logits de clasificar el dígito en una de las 10 classes,\n",
    "    y keep_prob un escalar placeholder para la probabilidad de dropout.\n",
    "  \"\"\"\n",
    "  \n",
    "  ####----------------- (1) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Reshape para usar input en una red convolucional (hint: se debe hacer un 'flatten' a 1D)\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    "  ####----------------- (2) COMPLETAR ---------------------#####\n",
    "    \n",
    "    with tf.name_scope('conv1'):\n",
    "        shape = [3, 3, 1, 32]\n",
    "        W_conv1 = weight_variable(shape)\n",
    "        b_conv1 = bias_variable([32])\n",
    "        # Ver el bloque de más abajo para las funciones conv2d, max_pool_2x2,\n",
    "        # weight_variable, y bias_variable\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    with tf.name_scope('conv2'):\n",
    "        shape = [3, 3, 32, 64]\n",
    "        W_conv2 = weight_variable(shape)\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    with tf.name_scope('fc1'):\n",
    "        layer_shape_in =  h_pool2.get_shape()\n",
    "        num_features_in = layer_shape_in[1:4].num_elements()\n",
    "        W_fc1 = weight_variable([num_features_in, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "\n",
    "        # El argumento -1 hace 'flatten' a 1D\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    " ####----------------- (3) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Implementar regularización por dropout\n",
    "    with tf.name_scope('dropout'):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, 0.9)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    " ####----------------- (4) COMPLETAR ---------------------#####\n",
    "    \n",
    "  # Map un número de features al número de clases\n",
    "    with tf.name_scope('cl_layer'):\n",
    "        W_fc2 = weight_variable([1024, 10])\n",
    "        b_fc2 = bias_variable([10])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    return y_conv\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUbF2VH85Gdk"
   },
   "source": [
    "A continuación se definen funciones que le serán útiles para la arquitectura definida en deep_nn():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zcvUIpw45Gdl"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    \"\"\"conv2d retorna una capa de convolución 2D con full stride\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"max_pool_2x2 hace downsample al feature map por 2X\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    " ####----------------- (5) COMPLETAR ---------------------##### \n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"weight_variable genera una variable de peso dadas ciertas dimensiones\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"bias_variable genera una variable de bias dado cierto shape\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6cq7z4x5Gdn"
   },
   "source": [
    "### 3) Fase de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQTAK1Wt5Gdp"
   },
   "source": [
    "En esta etapa, antes de ejecutar la sesión deberá definir los name scopes de:\n",
    "+ 'loss': función de costos a optimizar <br>\n",
    "+ 'my_optimizer': algoritmo de optimización e hiperparámetros que utilizará en el entrenamiento <br>\n",
    "Algunas opciones (se valorizará el uso de un algoritmo distinto al mostrado en el tutorial):\n",
    "> + __Descenso por el gradiente__, __descenso estocástico por el gradiente__, __descenso por el gradiente con mini-batches__: https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer <br>\n",
    "> + __RMSProp__ (algoritmo con momentum): https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer <br>\n",
    "> + __Adagrad__ (algoritmo con learning rates adaptativos): https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer <br>\n",
    "> + __Adam__ (algoritmo con momentum y learning rates adaptativos): https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer <br>\n",
    "+ 'accuracy': métrica de desempeño\n",
    "\n",
    "__Tenga en consideración que la siguiente etapa puede tomar una cantidad significativa de tiempo (3 min ~ 1,000 epochs)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1583
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 597447,
     "status": "ok",
     "timestamp": 1526747863457,
     "user": {
      "displayName": "Martín Cornejo-Saavedra",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100137397923643336617"
     },
     "user_tz": 240
    },
    "id": "fSklYsg75Gdp",
    "outputId": "b691a9d6-d55c-4380-c421-6d46d394f223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Saving graph to: /tmp/tmpod_e6eoh\n",
      "step 0, training set accuracy 0.17\n",
      "validation set accuracy 0.117\n",
      "test set accuracy 0.1151\n",
      "step 100, training set accuracy 0.9\n",
      "validation set accuracy 0.922\n",
      "test set accuracy 0.9219\n",
      "step 200, training set accuracy 0.97\n",
      "validation set accuracy 0.951\n",
      "test set accuracy 0.9506\n",
      "step 300, training set accuracy 0.95\n",
      "validation set accuracy 0.9624\n",
      "test set accuracy 0.9602\n",
      "step 400, training set accuracy 0.94\n",
      "validation set accuracy 0.9608\n",
      "test set accuracy 0.9583\n",
      "step 500, training set accuracy 0.97\n",
      "validation set accuracy 0.972\n",
      "test set accuracy 0.9694\n",
      "step 600, training set accuracy 0.98\n",
      "validation set accuracy 0.9724\n",
      "test set accuracy 0.9734\n",
      "step 700, training set accuracy 0.98\n",
      "validation set accuracy 0.977\n",
      "test set accuracy 0.9761\n",
      "step 800, training set accuracy 0.97\n",
      "validation set accuracy 0.977\n",
      "test set accuracy 0.9772\n",
      "step 900, training set accuracy 0.96\n",
      "validation set accuracy 0.9764\n",
      "test set accuracy 0.9748\n",
      "step 1000, training set accuracy 0.98\n",
      "validation set accuracy 0.9794\n",
      "test set accuracy 0.9795\n",
      "step 1100, training set accuracy 0.95\n",
      "validation set accuracy 0.975\n",
      "test set accuracy 0.9753\n",
      "step 1200, training set accuracy 0.99\n",
      "validation set accuracy 0.9814\n",
      "test set accuracy 0.9799\n",
      "step 1300, training set accuracy 0.98\n",
      "validation set accuracy 0.9786\n",
      "test set accuracy 0.977\n",
      "step 1400, training set accuracy 0.99\n",
      "validation set accuracy 0.9842\n",
      "test set accuracy 0.982\n",
      "step 1500, training set accuracy 0.99\n",
      "validation set accuracy 0.9844\n",
      "test set accuracy 0.9829\n",
      "step 1600, training set accuracy 0.99\n",
      "validation set accuracy 0.9856\n",
      "test set accuracy 0.9836\n",
      "step 1700, training set accuracy 0.97\n",
      "validation set accuracy 0.985\n",
      "test set accuracy 0.9824\n",
      "step 1800, training set accuracy 1\n",
      "validation set accuracy 0.9846\n",
      "test set accuracy 0.9837\n",
      "step 1900, training set accuracy 1\n",
      "validation set accuracy 0.9836\n",
      "test set accuracy 0.9821\n",
      "step 2000, training set accuracy 0.98\n",
      "validation set accuracy 0.9846\n",
      "test set accuracy 0.9846\n",
      "step 2100, training set accuracy 0.97\n",
      "validation set accuracy 0.9844\n",
      "test set accuracy 0.9848\n",
      "step 2200, training set accuracy 0.99\n",
      "validation set accuracy 0.9838\n",
      "test set accuracy 0.9843\n",
      "step 2300, training set accuracy 0.99\n",
      "validation set accuracy 0.9864\n",
      "test set accuracy 0.9848\n",
      "step 2400, training set accuracy 0.99\n",
      "validation set accuracy 0.9862\n",
      "test set accuracy 0.9851\n",
      "step 2500, training set accuracy 1\n",
      "validation set accuracy 0.987\n",
      "test set accuracy 0.9874\n",
      "step 2600, training set accuracy 0.98\n",
      "validation set accuracy 0.9848\n",
      "test set accuracy 0.9828\n",
      "step 2700, training set accuracy 0.98\n",
      "validation set accuracy 0.9872\n",
      "test set accuracy 0.9854\n"
     ]
    }
   ],
   "source": [
    "# Función que realiza la fase de ejecución\n",
    "def main(mnist_data):\n",
    "    # Importar datos\n",
    "    mnist = input_data.read_data_sets(mnist_data)\n",
    "    \n",
    " ####----------------- (6) COMPLETAR ---------------------#####\n",
    "\n",
    "    # Inputs, etiquetas, y output de la red convolucional\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28*28))\n",
    "\n",
    "\n",
    "    y_ = tf.placeholder(tf.int64, shape=(None))\n",
    "\n",
    "    y_conv = deepnn(x)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    " ####----------------- (7) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Función objetivo, optimizador y evaluación\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                              logits=y_conv)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('my_optimizer'):\n",
    "        learning_rate=0.1\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train_step = train_step.minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    "    graph_location = tempfile.mkdtemp()\n",
    "    print('Saving graph to: %s' % graph_location)\n",
    "    train_writer = tf.summary.FileWriter(graph_location)\n",
    "    train_writer.add_graph(tf.get_default_graph())\n",
    "\n",
    " ####----------------- (8) COMPLETAR ---------------------#####\n",
    "    \n",
    "    batch_size = 100\n",
    "    n_epochs = 5\n",
    "    batches_per_epoch = int(mnist.train.num_examples / batch_size)\n",
    "#     pdb.set_trace()\n",
    "    probabilidad = tf.constant(1, dtype=tf.float32)\n",
    "    \n",
    "    # Ejecutar la sesión que entrena la red convolucional\n",
    "    with tf.Session() as sess:\n",
    "        #Inicialice las variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        init.run()        \n",
    "        for i in range(n_epochs * batches_per_epoch):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Imprimir métricas cada 100 epochs\n",
    "            if i % 100 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x: X_batch, y_: y_batch})\n",
    "                print('step %d, training set accuracy %g' % (i, train_accuracy))\n",
    "                validation_accuracy = accuracy.eval(feed_dict={x: mnist.validation.images,\n",
    "                                            y_: mnist.validation.labels})\n",
    "                print('validation set accuracy %g' % validation_accuracy)\n",
    "                test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images,\n",
    "                                            y_: mnist.test.labels})\n",
    "                print('test set accuracy %g' % test_accuracy)\n",
    "            # El argumento keep_prob indica la probabilidad de mantener un nodo de input\n",
    "            # (es dropout aplicado al input)            \n",
    "            sess.run(train_step, feed_dict={x: X_batch, y_: y_batch})\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    "# Esta parte del código ejecuta la función main(). No necesitas modificarla\n",
    "#if __name__ == '__main__':\n",
    "#    parser = argparse.ArgumentParser()\n",
    "#    parser.add_argument('--data_dir', type=str,\n",
    "#                      default='/tmp/tensorflow/mnist/input_data',\n",
    "#                      help='Directory for storing input data')\n",
    "#    FLAGS, unparsed = parser.parse_known_args()\n",
    "#    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
    "main(\"/tmp/tensorflow/mnist/input_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA5jP1PR5Gdu"
   },
   "source": [
    "### 4) Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bNXYtGs5Gdu"
   },
   "source": [
    "Muestre curvas de aprendizaje (e.g., pérdida en función de épocas), comparación entre los distintos sets, matrices de confusión y análisis de error en el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EM1M_MMP5Gdv"
   },
   "source": [
    "## Proyecto (25%)\n",
    "\n",
    "Defina sucintamente el objetivo de su proyecto, enmárquelo en alguna de las temáticas del curso (regresión, clasificación, clustering, reducción de dimensionalidad, etc.) e identifique sus datos con la notación vista en clase (e.g., defina sus _inputs_ y _labels_ si su problema es de clasificación). Además, explore las herramientas clásicas para resolver su problema e implemente al menos una con sus datos. \n",
    "\n",
    "Extensión máxima para esta parte: **2 páginas**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Tarea_4_MA5203.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
