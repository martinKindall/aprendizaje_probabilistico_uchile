{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea #4: MA5203 Aprendizaje de Máquinas Probabilístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Redes Neuronales y MNIST (75%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tarea deberán implementar una __red neuronal convolucional__ (CNN) profunda para resolver el problema de clasificación de las imágenes de dígitos escritos a mano (MNIST), en donde se espera que alcancen mayores niveles de accuracy que con la red neuronal feedforward mostrada en el tutorial de TensorFlow.\n",
    "\n",
    "Para esto:\n",
    "> + Diseñarán la arquitectura de una red convolucional <br>\n",
    "> + Ajustarán un algoritmo de optimización de su preferencia <br>\n",
    "> + Regularizarán la red neuronal <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1) Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debe entregar el Jupyter Notebook completando en el código las secciones indicadas y señalizadas específicamente por (...). Puede agregar o quitar partes del diseño de la arquitectura como estime conveniente. También deberá entregar un informe de __máximo 2 planas__ que incluya:\n",
    "\n",
    "> + Arquitectura de la red <br>\n",
    "> + Ajuste de hiperparámetros y optimizador elegido<br>\n",
    "> + Regularización y entrenamiento <br>\n",
    "> + Presentación de resultados <br>\n",
    "> + Análisis de resultados y conclusiones <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Fase de construcción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera función a construir es _deepnn()_, que construye el grafo con la arquitectura de la red convolucional con la que se resolverá el problema. Esta debe contener la siguiente estructura (como mínimo) dentro de los _name scopes_:\n",
    "+ 'reshape': haz un reshape al input para usarlo dentro de una red convolucional (https://www.tensorflow.org/api_docs/python/tf/reshape) <br>\n",
    "+ capa de convolución (se recomienda más de 1):\n",
    "> + 'conv': capa de convolución <br>\n",
    "> + 'pool': capa de pooling <br>\n",
    "> + 'fc': capa fully connected <br>\n",
    "+ 'droput': máscara de dropout para regularización (puede usar otra técnica) (https://www.tensorflow.org/api_docs/python/tf/nn/dropout) <br>\n",
    "+ 'cl_layer': capa de clasificación <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "    \"\"\"\n",
    "  Función que construye el grafo de una red profunda\n",
    "  \n",
    "  --------PUEDE AGREGAR O QUITAR ELEMENTOS DE LA CAPA PREDEFINIDA MÁS ADELANTE------\n",
    "  \n",
    "  Args:\n",
    "    x: tensor de input con dimensiones (N_examples, 784)\n",
    "  Returns:\n",
    "    Una tupla (y, keep_prob), con y un tensor de dimensión (N_examples, 10),\n",
    "    con los valores de los logits de clasificar el dígito en una de las 10 classes,\n",
    "    y keep_prob un escalar placeholder para la probabilidad de dropout.\n",
    "  \"\"\"\n",
    "  \n",
    "  ####----------------- (1) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Reshape para usar input en una red convolucional (hint: se debe hacer un 'flatten' a 1D)\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    "  ####----------------- (2) COMPLETAR ---------------------#####\n",
    "    \n",
    "    with tf.name_scope('conv1'):\n",
    "        shape = [3, 3, 1, 32]\n",
    "        W_conv1 = weight_variable(shape)\n",
    "        b_conv1 = bias_variable([32])\n",
    "        # Ver el bloque de más abajo para las funciones conv2d, max_pool_2x2,\n",
    "        # weight_variable, y bias_variable\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    with tf.name_scope('conv2'):\n",
    "        shape = [3, 3, 32, 64]\n",
    "        W_conv2 = weight_variable(shape)\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    with tf.name_scope('fc1'):\n",
    "        layer_shape_in =  h_pool2.get_shape()\n",
    "        num_features_in = layer_shape_in[1:4].num_elements()\n",
    "        W_fc1 = weight_variable([num_features_in, 250])\n",
    "        b_fc1 = bias_variable([250])\n",
    "\n",
    "        # El argumento -1 hace 'flatten' a 1D\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    " ####----------------- (3) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Implementar regularización por dropout\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = ...\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    " ####----------------- (4) COMPLETAR ---------------------#####\n",
    "    \n",
    "  # Map un número de features al número de clases\n",
    "    with tf.name_scope('cl_layer'):\n",
    "        W_fc2 = weight_variable([250, 10])\n",
    "        b_fc2 = bias_variable([10])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    return y_conv, keep_prob\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se definen funciones que le serán útiles para la arquitectura definida en deep_nn():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    \"\"\"conv2d retorna una capa de convolución 2D con full stride\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"max_pool_2x2 hace downsample al feature map por 2X\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    " ####----------------- (5) COMPLETAR ---------------------##### \n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"weight_variable genera una variable de peso dadas ciertas dimensiones\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"bias_variable genera una variable de bias dado cierto shape\"\"\"\n",
    "    initial = tf.constant(0.05, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Fase de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta etapa, antes de ejecutar la sesión deberá definir los name scopes de:\n",
    "+ 'loss': función de costos a optimizar <br>\n",
    "+ 'my_optimizer': algoritmo de optimización e hiperparámetros que utilizará en el entrenamiento <br>\n",
    "Algunas opciones (se valorizará el uso de un algoritmo distinto al mostrado en el tutorial):\n",
    "> + __Descenso por el gradiente__, __descenso estocástico por el gradiente__, __descenso por el gradiente con mini-batches__: https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer <br>\n",
    "> + __RMSProp__ (algoritmo con momentum): https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer <br>\n",
    "> + __Adagrad__ (algoritmo con learning rates adaptativos): https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer <br>\n",
    "> + __Adam__ (algoritmo con momentum y learning rates adaptativos): https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer <br>\n",
    "+ 'accuracy': métrica de desempeño\n",
    "\n",
    "__Tenga en consideración que la siguiente etapa puede tomar una cantidad significativa de tiempo (3 min ~ 1,000 epochs)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Función que realiza la fase de ejecución\n",
    "def main(mnist_data):\n",
    "    # Importar datos\n",
    "    mnist = input_data.read_data_sets(FLAGS.data_dir)\n",
    "\n",
    " ####----------------- (6) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Inputs, etiquetas, y output de la red convolucional\n",
    "    x = tf.placeholder(tf.float32, [..., ...])\n",
    "\n",
    "    y_ = tf.placeholder(tf.int64, [...])\n",
    "\n",
    "    y_conv, keep_prob = ...\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    " ####----------------- (7) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Función objetivo, optimizador y evaluación\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = ...\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('my_optimizer'):\n",
    "        train_step = ...\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = ...\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "\n",
    "    graph_location = tempfile.mkdtemp()\n",
    "    print('Saving graph to: %s' % graph_location)\n",
    "    train_writer = tf.summary.FileWriter(graph_location)\n",
    "    train_writer.add_graph(tf.get_default_graph())\n",
    "\n",
    " ####----------------- (8) COMPLETAR ---------------------#####\n",
    "    \n",
    "    # Ejecutar la sesión que entrena la red convolucional\n",
    "    with tf.Session() as sess:\n",
    "        #Inicialice las variables\n",
    "        ...\n",
    "        for i in range(...):\n",
    "            X_batch, y_batch = mnist.train.next_batch(...)\n",
    "            # Imprimir métricas cada 100 epochs\n",
    "            if i % 100 == 0:\n",
    "                train_accuracy = ...\n",
    "                print('step %d, training set accuracy %g' % (i, train_accuracy))\n",
    "                validation_accuracy = ...\n",
    "                print('validation set accuracy %g' % validation_accuracy)\n",
    "                test_accuracy = ...\n",
    "                print('test set accuracy %g' % test_accuracy)\n",
    "            # El argumento keep_prob indica la probabilidad de mantener un nodo de input\n",
    "            # (es dropout aplicado al input)\n",
    "            train_step.run(feed_dict={x: ..., y_: ..., keep_prob: ...})\n",
    "        \n",
    "  ####---------------- fin completar -----------------#####\n",
    "            \n",
    "# Esta parte del código ejecuta la función main(). No necesitas modificarla\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str,\n",
    "                      default='/tmp/tensorflow/mnist/input_data',\n",
    "                      help='Directory for storing input data')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4) Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestre curvas de aprendizaje (e.g., pérdida en función de épocas), comparación entre los distintos sets, matrices de confusión y análisis de error en el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto (25%)\n",
    "\n",
    "Defina sucintamente el objetivo de su proyecto, enmárquelo en alguna de las temáticas del curso (regresión, clasificación, clustering, reducción de dimensionalidad, etc.) e identifique sus datos con la notación vista en clase (e.g., defina sus _inputs_ y _labels_ si su problema es de clasificación). Además, explore las herramientas clásicas para resolver su problema e implemente al menos una con sus datos. \n",
    "\n",
    "Extensión máxima para esta parte: **2 páginas**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
